{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-refinement of multiple contrast DMPC datasets in *refnx*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook demonstrates the utility of the *refnx* package for analysis of neutron reflectometry data. Specifically:\n",
    "\n",
    " - the co-refinement of three contrast variation datasets of a DMPC (1,2-dimyristoyl-sn-glycero-3-phosphocholine) bilayer measured at the solid-liquid interface with a common model\n",
    " - the use of the `LipidLeaflet` component to parameterise the model in terms of physically relevant parameters\n",
    " - the use of Bayesian Markov Chain Monte Carlo (MCMC) to investigate the Posterior distribution of the curvefitting system.\n",
    " - the intrinsic usefulness of Jupyter notebooks to facilitate reproducible research in scientific data analysis\n",
    " \n",
    " <img src=\"DMPC.png\">\n",
    " \n",
    " The images produced in this notebook are used directly in production of the *refnx* paper.\n",
    " \n",
    " The Jupyter notebook are executable documents that can be distributed, enabling others to reproduce the data analysis contained in the document. The *refnx* documentation at https://refnx.readthedocs.io/en/latest/index.html can be consulted for further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in most Python scripts is to import modules and functions that are going to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use matplotlib for plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "import refnx, scipy\n",
    "\n",
    "# the analysis module contains the curvefitting engine\n",
    "from refnx.analysis import CurveFitter, Objective, Parameter, GlobalObjective, process_chain\n",
    "\n",
    "# the reflect module contains functionality relevant to reflectometry\n",
    "from refnx.reflect import SLD, ReflectModel, Structure, LipidLeaflet\n",
    "\n",
    "# the ReflectDataset object will contain the data\n",
    "from refnx.dataset import ReflectDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the analysis to be exactly reproducible the same package versions must be used. The *conda* packaging manager, and *pip*, can be used to ensure this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.1.7.dev0+d5b9440', '1.3.0.dev0+6cd8536')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version numbers used in this analysis\n",
    "refnx.version.version, scipy.version.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ReflectDataset` class is used to represent a dataset. They can be constructed by supplying a filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d2o = ReflectDataset('c_PLP0016596.dat')\n",
    "data_d2o.name = \"d2o\"\n",
    "\n",
    "data_hdmix = ReflectDataset('c_PLP0016601.dat')\n",
    "data_hdmix.name = \"hdmix\"\n",
    "\n",
    "data_h2o = ReflectDataset('c_PLP0016607.dat')\n",
    "data_h2o.name = \"h2o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `SLD` object is used to represent the Scattering Length Density of a material. It has `real` and `imag` attributes because the SLD is a complex number, with the imaginary part accounting for absorption. The units of SLD are $10^{-6} \\mathring{A}^{-2}$\n",
    "\n",
    "The `real` and `imag` attributes are `Parameter` objects. These `Parameter` objects contain the: parameter value, whether it allowed to vary, any interparameter constraints, and bounds applied to the parameter. The bounds applied to a parameter are probability distributions which encode the log-prior probability of the parameter having a certain value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = SLD(2.07 + 0j)\n",
    "sio2 = SLD(3.47 + 0j)\n",
    "\n",
    "# the following represent the solvent contrasts used in the experiment\n",
    "d2o = SLD(6.36 + 0j)\n",
    "h2o = SLD(-0.56 + 0j)\n",
    "hdmix = SLD(2.07 + 0j)\n",
    "\n",
    "# We want the `real` attribute parameter to vary in the analysis, and we want to apply\n",
    "# uniform bounds. The `setp` method of a Parameter is a way of changing many aspects of\n",
    "# Parameter behaviour at once.\n",
    "d2o.real.setp(vary=True, bounds=(6.1, 6.36))\n",
    "d2o.real.name='d2o SLD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LipidLeaflet` class is used to describe a single lipid leaflet in our interfacial model. A leaflet consists of a head and tail group region. Since we are studying a bilayer then inner and outer `LipidLeaflet`'s are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter for the area per molecule each DMPC molecule occupies at the surface. We\n",
    "# use the same area per molecule for the inner and outer leaflets.\n",
    "apm = Parameter(56, 'area per molecule', vary=True, bounds=(52, 65))\n",
    "\n",
    "# the sum of scattering lengths for the lipid head and tail in Angstrom.\n",
    "b_heads = Parameter(6.01e-4, 'b_heads')\n",
    "b_tails = Parameter(-2.92e-4, 'b_tails')\n",
    "\n",
    "# the volume occupied by the head and tail groups in cubic Angstrom.\n",
    "v_heads = Parameter(319, 'v_heads')\n",
    "v_tails = Parameter(782, 'v_tails')\n",
    "\n",
    "# the head and tail group thicknesses.\n",
    "inner_head_thickness = Parameter(9, 'inner_head_thickness', vary=True, bounds=(4, 11))\n",
    "outer_head_thickness = Parameter(9, 'outer_head_thickness', vary=True, bounds=(4, 11))\n",
    "tail_thickness = Parameter(14, 'tail_thickness', vary=True, bounds=(10, 17))\n",
    "\n",
    "# finally construct a `LipidLeaflet` object for the inner and outer leaflets.\n",
    "# Note that here the inner and outer leaflets use the same area per molecule,\n",
    "# same tail thickness, etc, but this is not necessary if the inner and outer\n",
    "# leaflets are different.\n",
    "inner_leaflet = LipidLeaflet(apm,\n",
    "                             b_heads, v_heads, inner_head_thickness,\n",
    "                             b_tails, v_tails, tail_thickness,\n",
    "                             3, 3)\n",
    "\n",
    "# we reverse the monolayer for the outer leaflet because the tail groups face upwards\n",
    "outer_leaflet = LipidLeaflet(apm,\n",
    "                             b_heads, v_heads, outer_head_thickness,\n",
    "                             b_tails, v_tails, tail_thickness,\n",
    "                             3, 0, reverse_monolayer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Slab` Component represents a layer of uniform scattering length density of a given thickness in our interfacial model. Here we make `Slabs` from `SLD` objects, but other approaches are possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slab constructed from SLD object.\n",
    "sio2_slab = sio2(15, 3)\n",
    "sio2_slab.thick.setp(vary=True, bounds=(2, 30))\n",
    "sio2_slab.thick.name = 'sio2 thickness'\n",
    "sio2_slab.rough.setp(vary=True, bounds=(0, 7))\n",
    "sio2_slab.rough.name = name='sio2 roughness'\n",
    "sio2_slab.vfsolv.setp(0.1, vary=True, bounds=(0., 0.5))\n",
    "sio2_slab.vfsolv.name = 'sio2 solvation'\n",
    "\n",
    "solv_roughness = Parameter(3, 'bilayer/solvent roughness')\n",
    "solv_roughness.setp(vary=True, bounds=(0, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the `Component`s have been constructed we can chain them together to compose a `Structure` object. The `Structure` object represents the interfacial structure of our system. We create different `Structure`s for each contrast. It is important to note that each of the `Structure`s share many components, such as the `LipidLeaflet` objects. This means that parameters used to construct those components are shared between all the `Structure`s, which enables co-refinement of multiple datasets. An alternate way to carry this out would be to apply constraints to underlying parameters, but this way is clearer. Note that the final component for each structure is a `Slab` created from the solvent `SLD`s, we give those slabs a zero thickness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_d2o = si | sio2_slab | inner_leaflet | outer_leaflet | d2o(0, solv_roughness)\n",
    "s_hdmix = si | sio2_slab | inner_leaflet | outer_leaflet | hdmix(0, solv_roughness)\n",
    "s_h2o = si | sio2_slab | inner_leaflet | outer_leaflet | h2o(0, solv_roughness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Structure`s created in the previous step describe the interfacial structure, these structures are used to create `ReflectModel` objects that know how to apply resolution smearing, scaling factors and background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d2o = ReflectModel(s_d2o)\n",
    "model_hdmix = ReflectModel(s_hdmix)\n",
    "model_h2o = ReflectModel(s_h2o)\n",
    "\n",
    "model_d2o.scale.setp(vary=True, bounds=(0.9, 1.1))\n",
    "\n",
    "model_d2o.bkg.setp(vary=True, bounds=(-5e-7, 1e-6))\n",
    "model_hdmix.bkg.setp(vary=True, bounds=(-5e-7, 1e-6))\n",
    "model_h2o.bkg.setp(vary=True, bounds=(-5e-7, 1e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `Objective` is constructed from a `ReflectDataset` and `ReflectModel`. Amongst other things `Objective`s can calculate chi-squared, log-likelihood probability, log-prior probability, etc. We then combine all the individual `Objective`s into a `GlobalObjective`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_d2o = Objective(model_d2o, data_d2o)\n",
    "objective_hdmix = Objective(model_hdmix, data_hdmix)\n",
    "objective_h2o = Objective(model_h2o, data_h2o)\n",
    "\n",
    "global_objective = GlobalObjective([objective_d2o, objective_hdmix, objective_h2o])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `CurveFitter` object can perform least squares fitting, or MCMC sampling on the `Objective` used to construct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = CurveFitter(global_objective, nwalkers=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialise the MCMC walkers by jittering around the best fit. Other modes of initialisation are possible: from a supplied covariance matrix, by sampling from the prior distributions, or by supplying known positions from an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we seed the numpy random number generator to get reproducible numbers\n",
    "# during walker initialisation\n",
    "np.random.seed(1)\n",
    "fitter.initialise('jitter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MCMC sampling a burn in period is used to allow the workers to be more representative of the distribution they are sampling. Here we do a number of samples, then discard them. The last chain position is kept to provide a starting point for the 'production' run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set random_state for reproducible pseudo-random number streams\n",
    "fitter.sample(1000, random_state=321);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the chain containing the samples is `(number_steps, number_walkers, number_parameters)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitter.chain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the start of the sampling run the walkers in the MCMC ensemble probably won't distributed according the distribution they are sampling. We can discard, or burn, the initial steps. Let's have a look at the steps for a parameter (e.g. the area-per-molecule) to see if they've reached equilibrium (i.e. distributed around a mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    plt.plot(fitter.chain[:, i, 5].flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it's hard to tell from this graph it seems that ~500 steps is enough for equilibration, so let's discard these initial steps that acted as the burn-in period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do a production sampling run.\n",
    "In this example the total number of samples is the number of walkers (200 by default) multiplied by the number of steps: 8000 * 200 = 1 600 000. The sampling engine automatically makes full use of the total number of processing cores available to it, but this is specifiable. In addition MPI can be used, which make it useful for sampling on a cluster - MCMC is embarrassingly parallel.\n",
    "Samples can be saved to file as they are acquired, useful for checkpointing sampling state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.sample(8000, random_state=123);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, successive steps are correlated to previous steps to some degree, and the chain should be thinned to ensure the samples are independent. Let's see how much we should thin by by looking at the autocorrelation of a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fitter.acf()[:, 5])\n",
    "plt.xlim(0, 1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sampling done here thinning by 400 should be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_chain(global_objective, fitter.chain, nthin=400);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling gives each varying parameter its own MCMC chain, which can be processed to give relevant statistics, or histogrammed, etc. The relationship between chains encodes the covariance of all the parameters. The chains are automatically processed to calculate the median of all the samples, and the half width of the [15.87, 84.13] percentiles. These two values are taken to be the 'fitted' parameter value, and its standard deviation. Each Parameter set to this median value, and given an `stderr` attribute.\n",
    "We can see those statistics by printing the objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(global_objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the 'fitted' models compare to the data. We could use `global_objective.plot()`, but because we want to do a bit more tweaking for the graphics (such as vertical offsets) we're going to create the graph manually. We're also going to examine the spread in the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmix_mult = 0.01\n",
    "h2o_mult = 0.1\n",
    "# the data\n",
    "plt.errorbar(data_d2o.x, data_d2o.y, data_d2o.y_err,\n",
    "             label='$\\mathregular{D_2O}$', ms=4, marker='o', lw=0, elinewidth=1)\n",
    "plt.errorbar(data_h2o.x, data_h2o.y * h2o_mult, data_h2o.y_err * h2o_mult,\n",
    "             label='$\\mathregular{H_2O}$', ms=4, marker='^', lw=0, elinewidth=1)\n",
    "plt.errorbar(data_hdmix.x, data_hdmix.y * hdmix_mult, data_hdmix.y_err * hdmix_mult,\n",
    "             label='$\\mathregular{HD_{mix}}$', ms=4, marker='^', lw=0, elinewidth=1)\n",
    "\n",
    "# the median of the posterior\n",
    "plt.plot(data_d2o.x, objective_d2o.generative(), color='r', zorder=20)\n",
    "plt.plot(data_hdmix.x, objective_hdmix.generative() * hdmix_mult, color='r', zorder=20)\n",
    "plt.plot(data_h2o.x, objective_h2o.generative() * h2o_mult, color='r', zorder=20)\n",
    "\n",
    "# plot the spread of the fits for the different datasets\n",
    "gen = global_objective.pgen(500)\n",
    "\n",
    "save_pars = np.copy(global_objective.parameters)\n",
    "for i in range(500):\n",
    "    global_objective.setp(next(gen))\n",
    "\n",
    "    plt.plot(data_d2o.x, objective_d2o.generative(),\n",
    "             color='k', alpha=0.02, zorder=10)\n",
    "    plt.plot(data_hdmix.x, objective_hdmix.generative() * hdmix_mult,\n",
    "             color='k', alpha=0.02, zorder=10)\n",
    "    plt.plot(data_h2o.x, objective_h2o.generative() * h2o_mult,\n",
    "             color='k', alpha=0.02, zorder=10)\n",
    "\n",
    "# put back the saved parameters\n",
    "global_objective.setp(save_pars)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.text(-0.04, 1e-11, 'a)')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Reflectivity')\n",
    "plt.xlabel('Q /$\\AA^{-1}$')\n",
    "plt.ylim(1e-10, 2);\n",
    "plt.xlim(0.004, 0.3)\n",
    "plt.savefig('global_fit.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can investigate the posterior distribution by a corner plot, this reveals interparameter covariances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "global_objective.corner();\n",
    "plt.savefig('corner.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variation in scattering length density profiles can be visualised by a little bit of processing. This enables one to see what range of SLD profiles are statistically possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_params = np.array(objective_d2o.parameters)\n",
    "\n",
    "z, median_sld = s_d2o.sld_profile()\n",
    "\n",
    "for pvec in objective_d2o.pgen(ngen=500):\n",
    "    objective_d2o.setp(pvec)\n",
    "    zs, sld = s_d2o.sld_profile()\n",
    "    plt.plot(zs, sld, color='k', alpha=0.05)\n",
    "\n",
    "# put back saved_params\n",
    "objective_d2o.setp(saved_params)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.text(-50, -1.6, 'b)')\n",
    "plt.plot(z, median_sld, lw=2, color='r');\n",
    "plt.ylabel('scattering length density / $10^{-6}\\AA^{-2}$')\n",
    "plt.xlabel('distance / $\\AA$')\n",
    "plt.savefig('d2o_sld_spread.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
